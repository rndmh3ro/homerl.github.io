<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  <link href="//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">



<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=0.5.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="nic,ethtool,driver,irqbalance," />





  <link rel="alternate" href="/atom.xml" title="Homer's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=0.5.0" />






<meta name="description" content="Resolve process
Upgrade firmware/driver
Driver parameter


Disable iptables
Improve ring buffer
Modify kernel network parameter sysctl.conf
Disable irqbalance, set the device irq affinity in local num">
<meta property="og:type" content="article">
<meta property="og:title" content="NIC issues">
<meta property="og:url" content="http://yoursite.com/2017/08/14/NIC-issues/index.html">
<meta property="og:site_name" content="Homer's Blog">
<meta property="og:description" content="Resolve process
Upgrade firmware/driver
Driver parameter


Disable iptables
Improve ring buffer
Modify kernel network parameter sysctl.conf
Disable irqbalance, set the device irq affinity in local num">
<meta property="og:updated_time" content="2017-12-31T17:13:11.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NIC issues">
<meta name="twitter:description" content="Resolve process
Upgrade firmware/driver
Driver parameter


Disable iptables
Improve ring buffer
Modify kernel network parameter sysctl.conf
Disable irqbalance, set the device irq affinity in local num">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>

  <title> NIC issues | Homer's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  








  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Homer's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-th fa-fw"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-user fa-fw"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags fa-fw"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tools">
          <a href="/tools" rel="section">
            
              <i class="menu-item-icon fa fa-heartbeat fa-fw"></i> <br />
            
            Tools
          </a>
        </li>
      
        
        <li class="menu-item menu-item-rss">
          <a href="/atom.xml" rel="section">
            
              <i class="menu-item-icon fa fa-rss fa-fw"></i> <br />
            
            Rss
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="#" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'K4XNzEUeT9VohamGXb51','2.0.0');
</script>



    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                NIC issues
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-08-14T19:46:34+08:00" content="2017-08-14">
              2017-08-14
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/network/" itemprop="url" rel="index">
                    <span itemprop="name">network</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/08/14/NIC-issues/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/14/NIC-issues/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h4 id="Resolve-process"><a href="#Resolve-process" class="headerlink" title="Resolve process"></a>Resolve process</h4><ul>
<li>Upgrade firmware/driver<ul>
<li>Driver parameter</li>
</ul>
</li>
<li>Disable iptables</li>
<li>Improve ring buffer</li>
<li>Modify kernel network parameter sysctl.conf</li>
<li>Disable irqbalance, set the device irq affinity in local numa node</li>
<li>Enable RPS/RFS/XPS</li>
<li>Enable performance mode</li>
</ul>
<h4 id="About-RSS"><a href="#About-RSS" class="headerlink" title="About RSS"></a><a href="http://blog.csdn.net/vah101/article/details/40077937" target="_blank" rel="external">About RSS</a></h4><p>For unsupport optical module<br>modprobe ixgbe allow_unsupported_sfp=1,1</p>
<p>Setting RSS queue<br>MQ:Disable or enable Multiple Queues, default 1 (array of int)<br>RSS:Number of Receive-Side Scaling Descriptor Queues, default 0=number of cpus (array of int)<br>modprobe ixgbe MQ=1,1 RSS=8,8</p>
<p>$ cat /etc/modprobe.d/ixgbe.conf<br>options ixgbe allow_unsupported_sfp=1,1<br>options ixgbe MQ=1,1 RSS=8,8<br>options ixgbe LRO=1<br>options ixgbe InterruptThrottleRate=20000,20000</p>
<p>InterruptThrottleRate:Maximum interrupts per second, per vector, (0,1,956-488281), default 1 (array of int)<br>LRO:Large Receive Offload (0,1), default 0 = off (array of int)</p>
<h4 id="Ethernet-Flow-Director"><a href="#Ethernet-Flow-Director" class="headerlink" title="Ethernet Flow Director"></a>Ethernet Flow Director</h4><p>ethtool -K eth2 ntuple on<br>ethtool –config-ntuple eth2 flow-type ip4 src-ip 192.168.100.1  action -1<br>ethtool –config-ntuple eth2 flow-type tcp4 src-port 80  action 2<br>ethtool –config-ntuple eth2 flow-type udp4 src-port 80  action 2</p>
<h4 id="Offload"><a href="#Offload" class="headerlink" title="Offload"></a>Offload</h4><p>ethtool -K ethX rx on  ## rx-checksuming tcp offload<br>ethtool -K ethX sg  ## tcp-sgmentation offloading<br><a href="https://www.mellanox.com/related-docs/prod_software/Performance_Tuning_Guide_for_Mellanox_Network_Adapters_Archive.pdf" target="_blank" rel="external">For 100GbE</a><br>In case “tx-nocache-copy” is enabled, (this is the case for some kernels, e.g. kernel 3.10,<br>which is the default for RH7.0) “tx-nocache-copy” should be disabled.<br>ethtool -K <interface> tx-nocache-copy off</interface></p>
<h4 id="Performance-mode"><a href="#Performance-mode" class="headerlink" title="Performance mode"></a>Performance mode</h4><h5 id="Get-numa-node"><a href="#Get-numa-node" class="headerlink" title="Get numa node"></a>Get numa node</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/class/net/[interface]/device/numa_node</span><br><span class="line">cat /sys/devices/[PCI root]/[PCIe <span class="keyword">function</span>]/numa_node</span><br></pre></td></tr></table></figure>
<h5 id="Enable-CPU-performance-mode"><a href="#Enable-CPU-performance-mode" class="headerlink" title="Enable CPU performance mode"></a>Enable CPU performance mode</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">grub parameter: intel_idle.max_cstate=0 processor.max_cstate=1</span><br><span class="line"></span><br><span class="line">cpupower idle-set <span class="_">-d</span> 4</span><br><span class="line">cpupower idle-set <span class="_">-d</span> 3</span><br><span class="line">cpupower idle-set <span class="_">-d</span> 2</span><br><span class="line">cpupower  frequency-set -g performance</span><br><span class="line">tuned-adm profile throughput-performance</span><br><span class="line">tuned-adm active</span><br><span class="line">or </span><br><span class="line"><span class="built_in">echo</span> performance &gt; /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</span><br><span class="line"></span><br><span class="line">cat /sys/devices/system/cpu/cpu*/cpufreq/cpuinfo_max_freq</span><br><span class="line">cat /sys/devices/system/cpu/cpu*/cpufreq/cpuinfo_cur_freq</span><br></pre></td></tr></table></figure>
<h4 id="Sysctl-conf"><a href="#Sysctl-conf" class="headerlink" title="Sysctl.conf"></a><a href="https://www.mellanox.com/related-docs/prod_software/Performance_Tuning_Guide_for_Mellanox_Network_Adapters_Archive.pdf" target="_blank" rel="external">Sysctl.conf</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">The following changes are recommended <span class="keyword">for</span> improving IPv4 traffic performance:</span><br><span class="line">Disable the TCP timestamps option <span class="keyword">for</span> better CPU utilization:</span><br><span class="line">sysctl -w net.ipv4.tcp_timestamps=0</span><br><span class="line"></span><br><span class="line">Enable the TCP selective acks option <span class="keyword">for</span> better throughput:</span><br><span class="line">With selective acknowledgments, the data receiver can inform the sender about all segments that have arrived successfully, so the sender need retransmit only the segments that have actually been lost.</span><br><span class="line">sysctl -w net.ipv4.tcp_sack=1</span><br><span class="line"></span><br><span class="line">Increase the maximum length of processor input queues:</span><br><span class="line">sysctl -w net.core.netdev_max_backlog=250000</span><br><span class="line"></span><br><span class="line">Increase the TCP maximum and default buffer sizes using setsockopt():</span><br><span class="line">sysctl -w net.core.rmem_max=4194304</span><br><span class="line">sysctl -w net.core.wmem_max=4194304</span><br><span class="line">sysctl -w net.core.rmem_default=4194304</span><br><span class="line">sysctl -w net.core.wmem_default=4194304</span><br><span class="line">sysctl -w net.core.optmem_max=4194304</span><br><span class="line"></span><br><span class="line">Increase memory thresholds to prevent packet dropping:</span><br><span class="line">sysctl -w net.ipv4.tcp_rmem=<span class="string">"4096 87380 4194304"</span></span><br><span class="line">sysctl -w net.ipv4.tcp_wmem=<span class="string">"4096 65536 4194304"</span></span><br><span class="line"></span><br><span class="line">Enable low latency mode <span class="keyword">for</span> TCP:</span><br><span class="line">sysctl -w net.ipv4.tcp_low_latency=1</span><br><span class="line"></span><br><span class="line">sysctl -w net.ipv4.tcp_adv_win_scale=1</span><br><span class="line">The following variable is used to tell the kernel how much of the socket buffer space should be used <span class="keyword">for</span> TCP window size, and how much to save <span class="keyword">for</span> an application buffer.</span><br><span class="line">A value of 1 means the socket buffer will be divided evenly between TCP windows size and application.</span><br></pre></td></tr></table></figure>
<h5 id="nic-interrupt-rates"><a href="#nic-interrupt-rates" class="headerlink" title="nic interrupt rates"></a><a href="https://www.ibm.com/support/knowledgecenter/en/SSQPD3_2.6.0/com.ibm.wllm.doc/usingethtoolrates.html" target="_blank" rel="external">nic interrupt rates</a></h5><ul>
<li>adaptive-rx Dynamic control to decrease RX latency at low packet rates and increase throughput at high packet rates</li>
<li>rx-usecs This is the number of microseconds to wait before raising an RX interrupt after a packet has been received. When rx-usecs is set to 0 rx-frames is used</li>
<li>rx-frames    This is the number of frames to queue up before raising an RX interrupt.</li>
<li>adaptive-tx Dynamic control to decrease TX latency at low packet rates and increase throughput at high packet rates</li>
<li>tx-usecs This is the number of microseconds to wait before raising an TX interrupt after a packet has been sent. When tx-usecs is set to 0 tx-frames is used</li>
<li>tx-frames This is the number of frames to queue up before raising an TX interrupt</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#10GbE 82599 setting</span></span><br><span class="line">ls /sys/class/net | egrep <span class="string">'(eth|en|p|em|br|bond)'</span> | <span class="keyword">while</span> <span class="built_in">read</span> nic</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  ethtool -C <span class="variable">$nic</span> rx-usecs 0 tx-usecs 0 adaptive-rx off adaptive-tx off <span class="comment">## there are some compatibility with a vendor 25GbE</span></span><br><span class="line">  ethtool -G <span class="variable">$nic</span> rx 4096/8192 tx 4096/8192 <span class="comment">#for latency, you could reduce the value,rx-ring,tx-ring #10GbE 82599, 25GbE , 50GbE has more</span></span><br><span class="line">  ethtool -N <span class="variable">$nic</span> rx-flow-hash udp4 sdfn</span><br><span class="line">  ifconfig <span class="variable">$nic</span> mtu 9000</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<h4 id="Check-command"><a href="#Check-command" class="headerlink" title="Check command"></a>Check command</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ip <span class="_">-s</span> <span class="_">-s</span> link/ifconfig</span><br><span class="line">ethttool -S dev | grep -Ei <span class="string">'err|miss|dis|drop|crc'</span></span><br><span class="line">sar -n DEV,ETCP 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># get firbe module detail</span></span><br><span class="line">ethttool -m dev </span><br><span class="line"></span><br><span class="line"><span class="comment">##Get them from</span></span><br><span class="line">/sys/class/net/em2/statistics/</span><br><span class="line">/proc/net/dev</span><br></pre></td></tr></table></figure>
<h4 id="RPS-RFS-for-not-support-RSS-ethernet-network-apapter"><a href="#RPS-RFS-for-not-support-RSS-ethernet-network-apapter" class="headerlink" title="RPS/RFS for not support RSS ethernet network apapter"></a>RPS/RFS for not support RSS ethernet network apapter</h4><h5 id="Check-the-device-support-RSS"><a href="#Check-the-device-support-RSS" class="headerlink" title="Check the device support RSS"></a>Check the device support RSS</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lspci -v <span class="_">-s</span> 83:00.0 | grep <span class="string">"MSI-X: Enable+"</span></span><br><span class="line">83:00.0 Ethernet controller: Intel Corporation 82599ES 10-Gigabit SFI/SFP+ Network Connection (rev 01)</span><br><span class="line">	Flags: bus master, fast devsel, latency 0, IRQ 247, NUMA node 1</span><br><span class="line">	I/O ports at d020 [size=32]</span><br><span class="line">	Capabilities: [50] MSI: Enable- Count=1/1 Maskable+ 64bit+</span><br><span class="line">	Capabilities: [70] MSI-X: Enable+ Count=64 Masked-</span><br></pre></td></tr></table></figure>
<p>I don’t know why there are some network adapter could not work well in 4 x numa node and in these server, all 25GbE adapter support RSS, some of vendor 4 x numa node is OK, there are the same network chip in each server, except they are the different OEM adapter<br>So I have to enabe RPS to get good performance, I guess it server design problem<br>There are about 10000~30000/s tcp retrans.</p>
<p>Here is the script for 4 x numa</p>
<p><a href="https://community.mellanox.com/docs/DOC-2820" target="_blank" rel="external">For interfaces that have a single queue or its number of queues is less than the number of NUMA node cores, it is recommended to configure the rps_cpus mask to the device NUMA node core list to gain the better parallelism of multi queue interfaces.</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/class/net/eth7/device/<span class="built_in">local</span>_cpus</span><br><span class="line">0000,000fffc0,00000000,0fffc000</span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">bond=bond0</span><br><span class="line">rfc=16392</span><br><span class="line">cc=$(grep -c processor /proc/cpuinfo)</span><br><span class="line">rsfe=$((<span class="variable">$cc</span>*<span class="variable">$rfc</span>))</span><br><span class="line"></span><br><span class="line">sysctl -w net.core.rps_sock_flow_entries=<span class="variable">$rsfe</span></span><br><span class="line">dmidecode -t system | grep -i huawei &amp;&amp; cat /proc/net/bonding/<span class="variable">$bond</span>  | awk <span class="string">'$0~/Slave Interface:/ &#123;print $NF&#125;'</span> | <span class="keyword">while</span> <span class="built_in">read</span> nic</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    node=$(cat /sys/class/net/<span class="variable">$nic</span>/device/numa_node)</span><br><span class="line">    [[ -z <span class="variable">$node</span> ]] &amp;&amp; <span class="built_in">echo</span> not found numa &amp;&amp; <span class="built_in">exit</span> 1</span><br><span class="line">    [[ -z <span class="variable">$nic</span> ]] &amp;&amp; <span class="built_in">echo</span> not found bond &amp;&amp; <span class="built_in">exit</span> 1</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"the nic is <span class="variable">$nic</span> in the node-<span class="variable">$node</span>"</span></span><br><span class="line">    service iptables stop</span><br><span class="line">    ethtool -G <span class="variable">$nic</span> rx 8192 tx 1024</span><br><span class="line">    ethtool -G <span class="variable">$nic</span> rx 8192 tx 1024</span><br><span class="line">    ethtool -K <span class="variable">$nic</span> lro on</span><br><span class="line">    ethtool -K <span class="variable">$bond</span> lro on</span><br><span class="line">    service irqbalance stop</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="variable">$node</span> ];<span class="keyword">then</span></span><br><span class="line">          <span class="built_in">echo</span> <span class="string">"bind int to node <span class="variable">$node</span>"</span></span><br><span class="line">          <span class="built_in">set</span>_irq_affinity_bynode.sh <span class="variable">$node</span> <span class="variable">$nic</span> <span class="comment">##### mlnx driver script</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> fileRps <span class="keyword">in</span> $(ls /sys/class/net/<span class="variable">$&#123;nic&#125;</span>/queues/rx-*/rps_cpus)</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">           [[ <span class="variable">$node</span> <span class="_">-eq</span> 1 ]] &amp;&amp; <span class="built_in">echo</span> 0000,00000000,00000000,0ff00000 &gt;<span class="variable">$fileRps</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> fileR<span class="built_in">fc</span> <span class="keyword">in</span> $(ls /sys/class/net/<span class="variable">$&#123;nic&#125;</span>/queues/rx-*/rps_flow_cnt)</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">           <span class="built_in">echo</span> <span class="variable">$rfc</span> &gt;<span class="variable">$fileRfc</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> fileRps <span class="keyword">in</span> $(ls /sys/class/net/<span class="variable">$&#123;nic&#125;</span>/queues/tx-*/xps_cpus)</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">           [[ <span class="variable">$node</span> <span class="_">-eq</span> 1 ]] &amp;&amp; <span class="built_in">echo</span> 0000,00000000,00000000,000<span class="built_in">fc</span>000 &gt;<span class="variable">$fileRps</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/performance_tuning_guide/network-rfs" target="_blank" rel="external">RFS</a> is disabled by default. To enable RFS, you must edit two files:<br>/proc/sys/net/core/rps_sock_flow_entries<br>Set the value of this file to the maximum expected number of concurrently active connections. We recommend a value of 32768 for moderate server loads. All values entered are rounded up to the nearest power of 2 in practice.<br>/sys/class/net/device/queues/rx-queue/rps_flow_cnt<br>Replace device with the name of the network device you wish to configure (for example, eth0), and rx-queue with the receive queue you wish to configure (for example, rx-0).<br>Set the value of this file to the value of rps_sock_flow_entries divided by N, where N is the number of receive queues on a device. For example, if rps_flow_entries is set to 32768 and there are 16 configured receive queues, rps_flow_cnt should be set to 2048. For single-queue devices, the value of rps_flow_cnt is the same as the value of rps_sock_flow_entries.<br>Data received from a single sender is not sent to more than one CPU. If the amount of data received from a single sender is greater than a single CPU can handle, configure a larger frame size to reduce the number of interrupts and therefore the amount of processing work for the CPU. Alternatively, consider NIC offload options or faster CPUs.</p>
<p><a href="http://www.simlinux.com/2017/02/28/net-softirq.html#RPS-RFS" target="_blank" rel="external">RPS</a>: 网卡驱动对每一个数据库包根据四元组(SIP,SPORT,DIP,DPORT)生成HASH值,通过HASH值将每个连接和CPU 绑定<br>RFS： 由于RPS只是单纯的把数据包均衡到不同的CPU上，此时如果应用程序所在CPU和中断处理的CPU不在同一个核，将会对CPU Cache影响很大，RFS的作用就是将应用程序和软中断处理分配到同一个CPU<br>XPS: 负载均衡选择网卡多队列发包<br>Data received from a single sender is not sent to more than one CPU. If the amount of data received from a single sender is greater than a single CPU can handle, configure a larger frame size to reduce the number of interrupts and therefore the amount of processing work for the CPU. Alternatively, consider NIC offload options or faster CPUs.<br>(Consider using numactl or taskset in conjunction with RFS to pin applications to specific cores, sockets, or NUMA nodes. This can help prevent packets from being processed out of order)[<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/performance_tuning_guide/network-rfs" target="_blank" rel="external">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/performance_tuning_guide/network-rfs</a>)</p>
<h4 id="RHEL-solutions"><a href="#RHEL-solutions" class="headerlink" title="RHEL solutions"></a><a href="https://access.redhat.com/solutions/21301" target="_blank" rel="external">RHEL solutions</a></h4><p>System dropping network packets</p>
<ul>
<li>High number of drop counters like drop, discard, err or error, fifo, buf or buffer, fail, miss, OOB, full counters in ethtool -S</li>
<li>High number of dropped, error, overrun, or frame counters in ifconfig</li>
<li>What is the first thing to try when I see my network interfaces dropping packets?<br>Root Cause<br>Counters like “discard” or “drop” in the output of ethtool -S ethX are caused by the exhaustion of the receive ring buffer.</li>
</ul>
<p>The ring buffer is a block of physical memory on the NIC.</p>
<p>Each packet received by the NIC is stored in this memory while an interrupt is sent to the kernel to fetch the packet into kernel memory.</p>
<p>If the available buffer is filling up faster than the kernel can take the packets, there will be discarded packets.</p>
<p>Verify packet loss with:<br>[root@host]# ip -s -s link<br>Verify discards/drops/etc with:<br>[root@host]# ethtool -S ethX<br>Verify RX ring buffer current and maximum settings with:<br>[root@host]# ethtool -g ethX</p>
<h5 id="0-05-packet-drop-rate"><a href="#0-05-packet-drop-rate" class="headerlink" title="0.05% packet drop rate"></a><a href="https://access.redhat.com/solutions/742043" target="_blank" rel="external">0.05% packet drop rate</a></h5><p>One of TCP’s main functions is to preserve a reliable data stream for applications by identifying and retrying any lost packets. It is normal operation for an underlying network to lose packets, for many different reasons, and for TCP be used and to hide this fact from application layers. Applications using unreliable transports (the major one being UDP) are expected to not care about the unreliability of the network. Applications which do care should use a reliable transport, eg. TCP (or more recently, SCTP) or implement their own reliability mechanisms.</p>
<p>The only impact of packet loss in the underlying network (which includes the device-drivers and lower network layer code which is counting the drops you are seeing) is a reduction in performance from the peak network speed. The reduction is dependent, non-linearly, on the packet drop ratio, and also on the traffic type. For bulk transfers (such as file-transfer) over TCP a drop ratio of under 0.1% results in a very small reduction in throughput – assuming that the Select Acknowledgement (SACK) TCP option is enabled on both systems. If SACK is disabled on either system there will be a measurable reduction in throughput if the drop rate exceeds 0.001%. On the other hand, thin stream traffic, where there is often no outstanding data for the transmitter to send, will be affected more as the need to retry lost packets will only be noticed after a time out rather than being detectable when data arrives out-of-order. Examples of thin-stream traffic include request-response and interactive connections.</p>
<h4 id="ifconfig-ip"><a href="#ifconfig-ip" class="headerlink" title="ifconfig/ip"></a><a href="https://unix.stackexchange.com/questions/184604/whats-the-difference-between-errors-dropped-overruns-and-frame-fiel" target="_blank" rel="external">ifconfig/ip</a></h4><ul>
<li><p>RX</p>
<ul>
<li><p>frame/length counts only misaligned frames, it means frames with a length not divisible by 8. Because of that length is not a valid frame and it is simply discarded (too-short frames and too-long frames)</p>
</li>
<li><p>overruns/fifo counts that times when there is fifo overruns, caused by the rate at which the buffer gets full and the kernel isn’t able to reclaim the buffer</p>
<ul>
<li>No cpu resource, interrupt not balance and not affinity, eg: all nic interrupt in core0</li>
</ul>
</li>
<li><p><a href="https://serverfault.com/questions/528290/ifconfig-eth0-rx-dropped-packets/601186" target="_blank" rel="external">dropped(normal) counts</a></p>
<ul>
<li>Softnet backlog full</li>
<li>Bad / Unintended VLAN tags</li>
<li>Unknown / Unregistered protocols</li>
<li>IPv6 frames when the server is not configured for IPv6</li>
</ul>
</li>
<li><p>dropped (in my opinion)</p>
<ul>
<li>Overloading</li>
<li>Hardware issue<ul>
<li>NIC ring buffer too slower</li>
<li>NIC/optical module issue</li>
<li>PCIE issue</li>
<li>Bad cable</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><a href="http://blog.hyfather.com/blog/2013/03/04/ifconfig/" target="_blank" rel="external">TX</a></p>
<ul>
<li>aborted transmission</li>
<li>errors due to carrirer</li>
<li>fifo err</li>
<li>heartbeat erros</li>
<li>window err</li>
<li>collisions is the number of transmissions terminated due to CSMA/CD (Carrier Sense Multiple Access with Collision Detection).</li>
</ul>
</li>
</ul>
<p>If NIC driver loss packages, linux don ‘t know, you can’t count it in linux<br>Some overrun(ifconfig) has the same means with dropped(ethtool)</p>
<ul>
<li><a href="https://lp007819.wordpress.com/2013/05/23/intel%E7%BD%91%E5%8D%A1%E7%8A%B6%E6%80%81%E7%BB%9F%E8%AE%A1%E7%96%91%E9%97%AE/" target="_blank" rel="external">rx_missed_errors</a><ul>
<li>real drop = rx_dropped(kernel drop) + rx_missed_errors<ul>
<li>To reduce DMA skb(socket buffer) to test, eg: ethtool -G eth1 rx 48, ethtool -G eth1 tx 48, there are a lot of rx_missed_err </li>
<li>这样看来rx_no_buffer_count 指的是在网卡通过DMA将设备FIFO中的skb-&gt;data传送到rx_buffer_info时，发现对应的rx_buffer_info还没有unmap，也就无法送到主存。说到底，这其实和软中断处理的速度有关。<br>猜测rx_missed_errors可能与硬中断有关。也就是在DMA传送完，发送硬中断之前，网卡的FIFO缓冲已经满了，导致接收的数据要立即丢掉。这个也可以验证：<br>首先卸载igb模块，然后insmod igb InterruptThrottleRate=10, 只让网卡每秒产生10个中断。关闭流控ethtool -A eth1 autoneg off , ethtool -A eth1 rx off , ethtool -A eth1 tx off ，再把DMA缓冲区调至最大ethtool -G eth1 rx 4096 , ethtool -G eth1 tx 4096。可以发现原来不增长或几乎不增长的rx_missed_errors 开始大幅增长，果然这个就是和网卡硬件的FIFO缓冲区有关。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="About-MPC-and-RNBC"><a href="#About-MPC-and-RNBC" class="headerlink" title="About MPC and RNBC"></a>About MPC and RNBC</h4><p>7.19.5 Missed Packets Count – MPC (0x4010; RC)<br>Counts the number of missed packets. Packets are missed when the receive FIFO has insufficient space<br>to store the incoming packet. This can be caused because of too few buffers allocated, or because there<br>is insufficient bandwidth on the PCI bus. Events setting this counter causes ICR.Rx Miss, the Receiver<br>Overrun Interrupt, to be set. This register does not increment if receives are not enabled.<br>These packets are also counted in the Total Packets Received register as well as in Total Octets<br>Received.</p>
<p>7.19.34 Receive No Buffers Count – RNBC (0x40A0; RC)<br>This register counts the number of times that frames were received when there were no available<br>buffers in host memory to store those frames (receive descriptor head and tail pointers were equal).<br>The packet is still received if there is space in the FIFO. This register only increments if receives are enabled (RCTL.RXEN is set).<br>This register does not increment when flow control packets are received.</p>
<h4 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h4><p><a href="http://jaseywang.me/2014/08/16/ifconfig-%E4%B8%8B%E9%9D%A2%E7%9A%84%E4%B8%80%E4%BA%9B%E5%AD%97%E6%AE%B5errors-dropped-overruns/" target="_blank" rel="external">ethtool</a></p>
<ul>
<li>Physical layer<ul>
<li>Speed</li>
<li>Duplex</li>
<li>CRC</li>
</ul>
</li>
</ul>
<p><a href="http://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html" target="_blank" rel="external">sar</a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sar -n TCP,ETCP 2</span><br><span class="line">02:47:30 AM  active/s passive/s    iseg/s    oseg/s</span><br><span class="line">02:47:31 AM      0.00      0.00      8.51      6.38</span><br><span class="line"></span><br><span class="line">02:47:30 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s</span><br><span class="line">02:47:31 AM      0.00      0.00      0.00      0.00      0.00</span><br></pre></td></tr></table></figure></p>
<p>active/s: Number of locally-initiated TCP connections per second (e.g., via connect()).<br>passive/s: Number of remotely-initiated TCP connections per second (e.g., via accept()).<br>retrans/s: Number of TCP retransmits per second.<br>The active and passive counts are often useful as a rough measure of server load: number of new accepted connections (passive), and number of downstream connections (active). It might help to think of active as outbound, and passive as inbound, but this isn’t strictly true (e.g., consider a localhost to localhost connection). </p>
<p>Retransmits are a sign of a network or server issue; it may be an unreliable network (e.g., the public Internet), or it may be due a server being overloaded and dropping packets. The example above shows just one new TCP connection per-second. </p>
<ul>
<li><a href="https://stackoverflow.com/questions/21113846/why-packet-drop-is-not-captured-under-ifconfig" target="_blank" rel="external">About iptables</a><ul>
<li>This is because iptables and ifconfig statistics refer to different layers in the protocol stack. ifconfig statistics are for the NIC (Physical and MAC layers) while iptables rules execute once frames are received by the NIC and delivered to the kernel (INPUT) or before the packet is delivered to layer 2 in the protocol stack (for OUTPUT)</li>
</ul>
</li>
</ul>
<h4 id="About-irqbalance"><a href="#About-irqbalance" class="headerlink" title="About irqbalance"></a><a href="https://community.mellanox.com/docs/DOC-2123" target="_blank" rel="external">About irqbalance</a></h4><p>Irqbalance is a Linux daemon that help to balance the CPU load generated by interrupts across all CPUs. Irqbalance identifies the highest volume interrupt sources, and isolates them to a single CPU, so that load is spread as much as possible over an entire processor set, while minimizing cache hit rates for irq handlers<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#debug irqbalance</span></span><br><span class="line">irqbalance <span class="_">-d</span> <span class="_">-f</span></span><br></pre></td></tr></table></figure></p>
<p><a href="https://access.redhat.com/sites/default/files/attachments/201501-perf-brief-low-latency-tuning-rhel7-v1.1.pdf" target="_blank" rel="external">perf-brief-low-latency-tuning-rhel7</a><br>The irqbalance service continues to be enabled by default in Red Hat Enterprise Linux 7. It<br>remains an important service that helps spread IRQ-processing load across multiple processors dynamically.</p>
<p>For more performance<br>here could be specific workloads or configuration where stopping irqbalance and using mlnx_tune is more optimal and recommended.</p>
<h4 id="About-interruptthrottlerate"><a href="#About-interruptthrottlerate" class="headerlink" title="About interruptthrottlerate"></a><a href="https://www.kernel.org/doc/Documentation/networking/e1000.txt" target="_blank" rel="external">About interruptthrottlerate</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Setting InterruptThrottleRate to a value greater or equal to 100</span><br><span class="line">will program the adapter to send out a maximum of that many interrupts</span><br><span class="line">per second, even <span class="keyword">if</span> more packets have come in. This reduces interrupt</span><br><span class="line">load on the system and can lower CPU utilization under heavy load,</span><br><span class="line">but will increase latency as packets are not processed as quickly.</span><br><span class="line"></span><br><span class="line">The default behaviour of the driver previously assumed a static</span><br><span class="line">InterruptThrottleRate value of 8000</span><br></pre></td></tr></table></figure>
<h4 id="About-LRO"><a href="#About-LRO" class="headerlink" title="About LRO"></a><a href="https://downloadmirror.intel.com/22919/eng/README.txt" target="_blank" rel="external">About LRO</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">LRO</span><br><span class="line">---</span><br><span class="line">Large Receive Offload (LRO) is a technique <span class="keyword">for</span> increasing inbound throughput</span><br><span class="line">of high-bandwidth network connections by reducing CPU overhead. It works by</span><br><span class="line">aggregating multiple incoming packets from a single stream into a larger </span><br><span class="line">buffer before they are passed higher up the networking stack, thus reducing</span><br><span class="line">the number of packets that have to be processed. LRO combines multiple </span><br><span class="line">Ethernet frames into a single receive <span class="keyword">in</span> the stack, thereby potentially </span><br><span class="line">decreasing CPU utilization <span class="keyword">for</span> receives.</span><br></pre></td></tr></table></figure>
<h4 id="Support-for-UDP-RSS"><a href="#Support-for-UDP-RSS" class="headerlink" title="Support for UDP RSS"></a><a href="https://downloadmirror.intel.com/22919/eng/README.txt" target="_blank" rel="external">Support for UDP RSS</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">   rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6</span><br><span class="line">     Retrieves the <span class="built_in">hash</span> options <span class="keyword">for</span> the specified network traffic type.</span><br><span class="line"></span><br><span class="line">  -N --config-nfc</span><br><span class="line">     Configures the receive network flow classification.</span><br><span class="line"></span><br><span class="line">   rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6 </span><br><span class="line">   m|v|t|s|d|f|n|r...</span><br><span class="line">     Configures the <span class="built_in">hash</span> options <span class="keyword">for</span> the specified network traffic type.</span><br><span class="line"></span><br><span class="line">     udp4    UDP over IPv4</span><br><span class="line">     udp6    UDP over IPv6</span><br><span class="line"></span><br><span class="line">     f   Hash on bytes 0 and 1 of the Layer 4 header of the rx packet.</span><br><span class="line">     n   Hash on bytes 2 and 3 of the Layer 4 header of the rx packet.</span><br><span class="line"></span><br><span class="line">The following is an example using udp4 (UDP over IPv4):</span><br><span class="line"></span><br><span class="line">  To include UDP port numbers <span class="keyword">in</span> RSS hashing run:</span><br><span class="line">     ethtool -N ethX rx-flow-hash udp4 sdfn</span><br><span class="line"></span><br><span class="line">  To exclude UDP port numbers from RSS hashing run:</span><br><span class="line">     ethtool -N ethX rx-flow-hash udp4 sd</span><br><span class="line"></span><br><span class="line">  To display UDP hashing current configuration run:</span><br><span class="line">     ethtool -n ethX rx-flow-hash udp4</span><br></pre></td></tr></table></figure>
<h3 id="Ethool-S"><a href="#Ethool-S" class="headerlink" title="Ethool -S"></a>Ethool -S</h3><h4 id="rx-tx-ring"><a href="#rx-tx-ring" class="headerlink" title="rx,tx-ring"></a>rx,tx-ring</h4><p>ethtool -G $nic rx 4096 tx 4096</p>
<p>rx_no_buffer_count,there was nowhere to DMA the packet<br>DMA skb-data to rx-buffer-info(linux RAM, soft-interrupt). </p>
<p>RNBC is a warning sign of a slow drain from the MAC and can be treated by adding more buffers.<br>There will be times when the RNBC will go up, but it will look like the stack and driver have a ton of buffers but work is not being done.  If you have a task that is eating up the CPU, the ISR or polling routines won’t refill the buffers fast enough and RNBC will happen.</p>
<p>Imagine we have a slow CPU, but a wicked fastbus.  The software is very slow to process the descriptors and return them, but once the descriptors are given to the hardware, it empties the backlog (read the FIFO) faster than the incoming frames are filling the FIFO.  Returning to our kitchen sink analogy, the water is coming in at a fairly constant rate.  But imagine the stopper is down, making the sink fill up.  Just before it over flows, the drain is opened and down it goes.  Once the water doesn’t go down the drain would be the same moment our RNBC would be incremented.  The kitchen sink itself becomes our FIFO and if the FIFO is big enough, it can save frame for quiet some time.  This is 1 Gigabit (or faster) that we’re talking about, so with a good sized FIFO (24K RX for example) that’s only 375 frames at 64 bytes, or 267microseconds of data.  That’s not very much time.  But in a world full of 2 and 3 Gigahertz CPUs that’s long enough.  </p>
<p>rx_missed_error,rx_no_buffer_count happened enough times that packets were dropped<br>MPC is a failure condition leading to dropped packets and can be treated with more buffers and faster interconnect buses</p>
<p>Thank goodness things like TCP/IP will tell the applications data has been dropped, but if using a lossy frame type like UDP its just too bad, your frame is lost to the ether. </p>
<p>Imagine if you will, an interconnect bus that is slow.  Very slow.  Like a PCI 33hz bus.  Now attach that to a full line rate 1 Gigabit 64 byte packet data stream.  At one descriptor per packet, that’s about 1.4 million descriptors per second.  In this case the software is very fast, faster than the bus.  So the number of available descriptors is always kept a level that keeps the buffers available to the hardware to conduct a DMA.  But because the bus is so slow, data backs up into the FIFO.  Now that is what the FIFO is for.  By buffering the packet, it tries to give the packet the best chance at making into host memory alive.  In our slow case, the buffering isn’t enough and the FIFO fills up.  It is draining slower than its filling, its just a like a slow draining kitchen sink.  Eventually it overflows and makes a big mess.  Thank goodness things like TCP/IP will tell the applications data has been dropped, but if using a lossy frame type like UDP its just too bad, your frame is lost to the ether.  If you need to keep track, but need to use UDP, you’ll need to monitor the MPC count and decide what you want to do when it goes up.</p>
<p>[猜测rx_missed_errors可能与硬中断有关。也就是在DMA传送完，发送硬中断之前，网卡的FIFO缓冲已经满了，导致接收的数据要立即丢掉。这个也可以验证：首先卸载igb模块，然后insmod igb InterruptThrottleRate=10, 只让网卡每秒产生10个中断。关闭流控ethtool -A eth1 autoneg off , ethtool -A eth1 rx off , ethtool -A eth1 tx off ，再把DMA缓冲区调至最大ethtool -G eth1 rx 4096 , ethtool -G eth1 tx 4096。可以发现原来不增长或几乎不增长的rx_missed_errors 开始大幅增长]<br>(<a href="https://lp007819.wordpress.com/2013/05/23/intel%E7%BD%91%E5%8D%A1%E7%8A%B6%E6%80%81%E7%BB%9F%E8%AE%A1%E7%96%91%E9%97%AE/" target="_blank" rel="external">https://lp007819.wordpress.com/2013/05/23/intel%E7%BD%91%E5%8D%A1%E7%8A%B6%E6%80%81%E7%BB%9F%E8%AE%A1%E7%96%91%E9%97%AE/</a>)</p>
<p>rx_fifo_errors,<br>rx_over_errors</p>
<h3 id="ifconfig"><a href="#ifconfig" class="headerlink" title="ifconfig"></a>ifconfig</h3><p>frame counts only misaligned frames, it means frames with a length not divisible by 8. Because of that length is not a valid frame and it is simply discarded.</p>
<p>Meanwhile errors counts CRC errors, too-short frames and too-long frames.</p>
<p>overruns counts that times when there is fifo overruns, caused by the rate at which the buffer gets full and the kernel isn’t able to empty it.</p>
<p>overruns<br>overruns，表示这个数据包还没有被进入到网卡的接收缓存fifo队列就被丢掉，因此此时网卡的fifo是满的。为什么fifo会是满的？因为系统繁忙，来不及响应网卡中断，导致网卡里的数据包没有及时的拷贝到系统内存，fifo是满的就导致后面的数据包进不来，即这个数据包被网卡硬件丢掉。所以，个人觉得遇到overruns非0，需要检测cpu负载与cpu中断情况。</p>
<p><a href="https://www.cisco.com/c/en/us/support/docs/dial-access/asynchronous-connections/15286-serial-overruns.html" target="_blank" rel="external">Q. What are overruns on a serial interface?</a></p>
<p>A. Overruns appear in the output of the show interface Serial 0 command when the serial receiver hardware is unable to hand received data to a hardware buffer because the input rate exceeds the receiver’s ability to handle the data.<br>This occurs due to a limitation of the hardware. Overruns occur when the internal First In, First Out (FIFO) buffer of the chip is full, but is still tries to handle incoming traffic. The serial controller chip has limited internal FIFO.<br>Some chips, for example, have only 256 bytes of buffer space. Data from the network is received into the buffer, whereupon the chip attempts to move the data from the buffer to the router’s shared memory for the CPU to process. If the chip is not able to move the data from its internal FIFO buffer into shared memory faster than the rate at which data is received on the interface, then the internal FIFO buffer is full, incoming data is dropped, and the overrun counter is incremented.</p>
<p>droppeds<br>dropped，表示这个数据包已经进入到网卡的接收缓存fifo队列，并且开始被系统中断处理准备进行数据包拷贝（从网卡缓存fifo队列拷贝到系统内存），但由于此时的系统原因（比如内存不够等）导致这个数据包被丢掉，即这个数据包被Linux系统丢掉。</p>
<h4 id="NFS-hangs"><a href="#NFS-hangs" class="headerlink" title="NFS hangs"></a>NFS hangs</h4><p>NFS server tcp zero window problem</p>
<p>Zero Window is something to investigate. TCP Zero Window is when the Window size in a machine remains at zero for a specified amount of time. This means that a client is not able to receive further information at the moment, and the TCP transmission is halted until it can process the information in its receive buffer.</p>
<h4 id="About-FEC"><a href="#About-FEC" class="headerlink" title="About FEC"></a><a href="http://www.qlogic.com/Resources/Documents/WhitePapers/Adapters/Localized/White_Paper-25Gb_Ethernet_SN0530917-05_CN.pdf" target="_blank" rel="external">About FEC</a></h4><p>IEEE 标准指定了两个底板和铜接口。这些接口的目标不同，因<br>此接口存在不同。–S 短距离接口旨在支持无需转发纠错（FEC）<br>的高质量电缆，以最大限度地降低延迟。全距离接口旨在实现<br>尽可能低的电缆或背板成本以及尽可能长的距离，这需要使用<br>FEC。FEC 选项包括 BASE-R FEC（也称为 Fire Code）和 RS-FEC（也<br>称为 Reed-Solomon）。RS-FEC 已用于一系列应用，包括数据存<br>储卫星传播。BASE-R FEC 是一种新型技术，特别适合纠正背板<br>通道中由于接收均衡器的错误传播而导致的突发错误。</p>

      
    </div>

    <div>
      
        
      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/nic/" rel="tag">#nic</a>
          
            <a href="/tags/ethtool/" rel="tag">#ethtool</a>
          
            <a href="/tags/driver/" rel="tag">#driver</a>
          
            <a href="/tags/irqbalance/" rel="tag">#irqbalance</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/07/31/upgrade-hgst-JBOD/" rel="next" title="upgrade hgst JBOD">
                <i class="fa fa-chevron-left"></i> upgrade hgst JBOD
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/08/25/About-nfs/" rel="prev" title="About_nfs">
                About_nfs <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/img/mq1-penn.jpg"
               alt="Homer Li" />
          <p class="site-author-name" itemprop="name">Homer Li</p>
          <p class="site-description motion-element" itemprop="description">The chioce you make, the risks you take</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">63</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>
          
          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">91</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/homerl/" target="_blank">
                  
                    <i class="fa fa-github"></i> GitHub
                  
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://plus.google.com/u/0/112219574615546910314" target="_blank">
                  
                    <i class="fa fa-globe"></i> G+
                  
                </a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="http://creativecommons.org/licenses/by-nc-sa/4.0" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator">
            <i class="fa fa-angle-double-up"></i>
          </div>
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#Resolve-process"><span class="nav-number">1.</span> <span class="nav-text">Resolve process</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#About-RSS"><span class="nav-number">2.</span> <span class="nav-text">About RSS</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ethernet-Flow-Director"><span class="nav-number">3.</span> <span class="nav-text">Ethernet Flow Director</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Offload"><span class="nav-number">4.</span> <span class="nav-text">Offload</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Performance-mode"><span class="nav-number">5.</span> <span class="nav-text">Performance mode</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Get-numa-node"><span class="nav-number">5.1.</span> <span class="nav-text">Get numa node</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Enable-CPU-performance-mode"><span class="nav-number">5.2.</span> <span class="nav-text">Enable CPU performance mode</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sysctl-conf"><span class="nav-number">6.</span> <span class="nav-text">Sysctl.conf</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#nic-interrupt-rates"><span class="nav-number">6.1.</span> <span class="nav-text">nic interrupt rates</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Check-command"><span class="nav-number">7.</span> <span class="nav-text">Check command</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RPS-RFS-for-not-support-RSS-ethernet-network-apapter"><span class="nav-number">8.</span> <span class="nav-text">RPS/RFS for not support RSS ethernet network apapter</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Check-the-device-support-RSS"><span class="nav-number">8.1.</span> <span class="nav-text">Check the device support RSS</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RHEL-solutions"><span class="nav-number">9.</span> <span class="nav-text">RHEL solutions</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#0-05-packet-drop-rate"><span class="nav-number">9.1.</span> <span class="nav-text">0.05% packet drop rate</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ifconfig-ip"><span class="nav-number">10.</span> <span class="nav-text">ifconfig/ip</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#About-MPC-and-RNBC"><span class="nav-number">11.</span> <span class="nav-text">About MPC and RNBC</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tools"><span class="nav-number">12.</span> <span class="nav-text">Tools</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#About-irqbalance"><span class="nav-number">13.</span> <span class="nav-text">About irqbalance</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#About-interruptthrottlerate"><span class="nav-number">14.</span> <span class="nav-text">About interruptthrottlerate</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#About-LRO"><span class="nav-number">15.</span> <span class="nav-text">About LRO</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Support-for-UDP-RSS"><span class="nav-number">16.</span> <span class="nav-text">Support for UDP RSS</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Ethool-S"><span class="nav-number"></span> <span class="nav-text">Ethool -S</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#rx-tx-ring"><span class="nav-number">1.</span> <span class="nav-text">rx,tx-ring</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ifconfig"><span class="nav-number"></span> <span class="nav-text">ifconfig</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#NFS-hangs"><span class="nav-number">1.</span> <span class="nav-text">NFS hangs</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#About-FEC"><span class="nav-number">2.</span> <span class="nav-text">About FEC</span></a></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator">
            <i class="fa fa-angle-double-down"></i>
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright" >
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Homer Li</span>
&nbsp&nbsp&nbsp Pageviews: <span id="busuanzi_value_site_pv"></span> &nbsp&nbsp&nbsp
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
&nbsp&nbsp&nbsp You are the <span id="busuanzi_value_site_uv"></span>th visitor &nbsp&nbsp&nbsp
</div>



      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  


  




<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=0.5.0"></script>



  
  

  
  
<script type="text/javascript" src="/js/src/scrollspy.js?v=0.5.0"></script>

<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      var $indicator = $(indicator);
      var opacity = action === 'show' ? 1 : 0;
      $indicator.velocity ?
        $indicator.velocity('stop').velocity({
          opacity: opacity
        }, { duration: 100 }) :
        $indicator.stop().animate({
          opacity: opacity
        }, 100);
    }

  });
</script>

<script type="text/javascript" id="sidebar.nav">
  $(document).ready(function () {
    var html = $('html');
    var TAB_ANIMATE_DURATION = 200;
    var hasVelocity = $.isFunction(html.velocity);

    $('.sidebar-nav li').on('click', function () {
      var item = $(this);
      var activeTabClassName = 'sidebar-nav-active';
      var activePanelClassName = 'sidebar-panel-active';
      if (item.hasClass(activeTabClassName)) {
        return;
      }

      var currentTarget = $('.' + activePanelClassName);
      var target = $('.' + item.data('target'));

      hasVelocity ?
        currentTarget.velocity('transition.slideUpOut', TAB_ANIMATE_DURATION, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', TAB_ANIMATE_DURATION)
            .addClass(activePanelClassName);
        }) :
        currentTarget.animate({ opacity: 0 }, TAB_ANIMATE_DURATION, function () {
          currentTarget.hide();
          target
            .stop()
            .css({'opacity': 0, 'display': 'block'})
            .animate({ opacity: 1 }, TAB_ANIMATE_DURATION, function () {
              currentTarget.removeClass(activePanelClassName);
              target.addClass(activePanelClassName);
            });
        });

      item.siblings().removeClass(activeTabClassName);
      item.addClass(activeTabClassName);
    });

    $('.post-toc a').on('click', function (e) {
      e.preventDefault();
      var targetSelector = NexT.utils.escapeSelector(this.getAttribute('href'));
      var offset = $(targetSelector).offset().top;
      hasVelocity ?
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        }) :
        $('html, body').stop().animate({
          scrollTop: offset
        }, 500);
    });

    // Expand sidebar on post detail page by default, when post has a toc.
    NexT.motion.middleWares.sidebar = function () {
      var $tocContent = $('.post-toc-content');

      if (CONFIG.scheme !== 'Pisces' && (CONFIG.sidebar.display === 'post' || CONFIG.sidebar.display === 'always')) {
        if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
          NexT.utils.displaySidebar();
        }
      }
    };
  });
</script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=0.5.0"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'homersblog';
      var disqus_identifier = '2017/08/14/NIC-issues/';
      var disqus_title = 'NIC issues';
      var disqus_url = 'http://yoursite.com/2017/08/14/NIC-issues/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        run_disqus_script('embed.js');
      
    </script>
  




  
  
  <script type="text/javascript">
    // Popup Window;
    var scrollTop = '';
    var newHeight = '100';

    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;

    // monitor main search box;
    $('#search-input').on('input', function() {
    if ($(this).val().length <= 0) {
      $('#search-result').hide();
      return;
    }
    $('i.search-keyword').text($(this).val());
    $('a.search-result[href!="#"]').each(function(){
      this.href = this.href.replace(/\=(.*?)(?=%20site)/,'='+$('#search-input').val())
    });
    $('#search-result').show();
    });

    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    searchFunc = function(){};
    $.ajax({
        url: path,
        dataType: "xml",
        async: false,
        success: function( xmlResponse ) {
            // get the contents from search data
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var str='<ul class=\"search-result-list\">';                
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length <= 0) {
                    return;
                }
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 100;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substr(start, end); 
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });
                            
                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                });
                str += "</ul>";
                $resultContent.innerHTML = str;
            });
        }
    });}

    // handle and trigger popup window;
    $(window).bind('scroll', function() {
      scrollTop = $( window ).scrollTop();
      newHeight = scrollTop + 100;
    });
    $('#search-result a').mousedown(function(e) {
        window.location.href = this.href;
      });
    $('.popup-trigger').mousedown(function(e) {
      searchFunc(path, 'local-search-input', 'local-search-result');
      $('#local-search-input').val($('#search-input').val());
      document.getElementById('local-search-input').dispatchEvent(new Event('input'));
      e.stopPropagation();
      if(jQuery(window).width() < 750) {
        $('.site-search-form').after( $( ".popup" ) );
        $('.popup').show().addClass('popup-mobile').css('top', 0);
        $('html, body').animate({
          scrollTop: $('.popup').offset().top
        }, 500);
      } else {
        $('.popup').removeClass('popup-mobile').css('top', newHeight).toggle();
      };
    });

    $('#search-input').focus(function() {
    if ($(this).val().length > 0) {
      $('#search-result').show();
      }
    });
    $('#search-input').blur(function() {
      $('#search-result').hide();
    });

    $('html').click(function() {
      $('.popup').hide();
    });
    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>

  

  


</body>
</html>
